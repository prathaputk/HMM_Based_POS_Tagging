{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "wsj = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')], [('Lorillard', 'NOUN'), ('Inc.', 'NOUN'), (',', '.'), ('the', 'DET'), ('unit', 'NOUN'), ('of', 'ADP'), ('New', 'ADJ'), ('York-based', 'ADJ'), ('Loews', 'NOUN'), ('Corp.', 'NOUN'), ('that', 'DET'), ('*T*-2', 'X'), ('makes', 'VERB'), ('Kent', 'NOUN'), ('cigarettes', 'NOUN'), (',', '.'), ('stopped', 'VERB'), ('using', 'VERB'), ('crocidolite', 'NOUN'), ('in', 'ADP'), ('its', 'PRON'), ('Micronite', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('in', 'ADP'), ('1956', 'NUM'), ('.', '.')], [('Although', 'ADP'), ('preliminary', 'ADJ'), ('findings', 'NOUN'), ('were', 'VERB'), ('reported', 'VERB'), ('*-2', 'X'), ('more', 'ADV'), ('than', 'ADP'), ('a', 'DET'), ('year', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('the', 'DET'), ('latest', 'ADJ'), ('results', 'NOUN'), ('appear', 'VERB'), ('in', 'ADP'), ('today', 'NOUN'), (\"'s\", 'PRT'), ('New', 'NOUN'), ('England', 'NOUN'), ('Journal', 'NOUN'), ('of', 'ADP'), ('Medicine', 'NOUN'), (',', '.'), ('a', 'DET'), ('forum', 'NOUN'), ('likely', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('bring', 'VERB'), ('new', 'ADJ'), ('attention', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('problem', 'NOUN'), ('.', '.')], [('A', 'DET'), ('Lorillard', 'NOUN'), ('spokewoman', 'NOUN'), ('said', 'VERB'), (',', '.'), ('``', '.'), ('This', 'DET'), ('is', 'VERB'), ('an', 'DET'), ('old', 'ADJ'), ('story', 'NOUN'), ('.', '.')], [('We', 'PRON'), (\"'re\", 'VERB'), ('talking', 'VERB'), ('about', 'ADP'), ('years', 'NOUN'), ('ago', 'ADP'), ('before', 'ADP'), ('anyone', 'NOUN'), ('heard', 'VERB'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('having', 'VERB'), ('any', 'DET'), ('questionable', 'ADJ'), ('properties', 'NOUN'), ('.', '.')], [('There', 'DET'), ('is', 'VERB'), ('no', 'DET'), ('asbestos', 'NOUN'), ('in', 'ADP'), ('our', 'PRON'), ('products', 'NOUN'), ('now', 'ADV'), ('.', '.'), (\"''\", '.')]]\n"
     ]
    }
   ],
   "source": [
    "# first few tagged sentences\n",
    "print(wsj[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('Yesterday', 'NOUN'), (\"'s\", 'PRT'), ('share', 'NOUN'), ('turnover', 'NOUN'), ('was', 'VERB'), ('well', 'ADV'), ('below', 'ADP'), ('the', 'DET'), ('year', 'NOUN'), (\"'s\", 'PRT'), ('daily', 'ADJ'), ('average', 'NOUN'), ('of', 'ADP'), ('133.8', 'NUM'), ('million', 'NUM'), ('.', '.')], [('Yet', 'ADV'), ('he', 'PRON'), ('is', 'VERB'), (\"n't\", 'ADV'), ('in', 'ADP'), ('favor', 'NOUN'), ('of', 'ADP'), ('new', 'ADJ'), ('legislation', 'NOUN'), ('.', '.')], [('Sea', 'NOUN'), ('Containers', 'NOUN'), ('Ltd.', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('might', 'VERB'), ('increase', 'VERB'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('its', 'PRON'), ('$', '.'), ('70-a-share', 'ADJ'), ('*U*', 'X'), ('buy-back', 'ADJ'), ('plan', 'NOUN'), ('if', 'ADP'), ('*-2', 'X'), ('pressed', 'VERB'), ('*-1', 'X'), ('by', 'ADP'), ('Temple', 'NOUN'), ('Holdings', 'NOUN'), ('Ltd.', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-156', 'X'), ('made', 'VERB'), ('an', 'DET'), ('earlier', 'ADJ'), ('tender', 'ADJ'), ('offer', 'NOUN'), ('for', 'ADP'), ('Sea', 'NOUN'), ('Containers', 'NOUN'), ('.', '.')], [('While', 'ADP'), ('U.S.', 'NOUN'), ('officials', 'NOUN'), ('voice', 'VERB'), ('optimism', 'NOUN'), ('about', 'ADP'), ('Japan', 'NOUN'), (\"'s\", 'PRT'), ('enlarged', 'ADJ'), ('role', 'NOUN'), ('in', 'ADP'), ('Asia', 'NOUN'), (',', '.'), ('they', 'PRON'), ('also', 'ADV'), ('convey', 'VERB'), ('an', 'DET'), ('undertone', 'NOUN'), ('of', 'ADP'), ('caution', 'NOUN'), ('.', '.')], [('Its', 'PRON'), ('1989-90', 'NUM'), ('exports', 'NOUN'), ('were', 'VERB'), ('expected', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('total', 'VERB'), ('645,000', 'NUM'), ('tons', 'NOUN'), ('in', 'ADP'), ('contrast', 'NOUN'), ('to', 'PRT'), ('shipments', 'NOUN'), ('of', 'ADP'), ('1.5', 'NUM'), ('million', 'NUM'), ('tons', 'NOUN'), ('in', 'ADP')], [('She', 'PRON'), ('said', 'VERB'), ('0', 'X'), ('there', 'DET'), ('is', 'VERB'), ('``', '.'), ('growing', 'VERB'), ('realization', 'NOUN'), ('*ICH*-1', 'X'), (\"''\", '.'), ('around', 'ADP'), ('the', 'DET'), ('world', 'NOUN'), ('that', 'DET'), ('denial', 'NOUN'), ('of', 'ADP'), ('intellectual-property', 'ADJ'), ('rights', 'NOUN'), ('harms', 'VERB'), ('all', 'DET'), ('trading', 'VERB'), ('nations', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('particularly', 'ADV'), ('the', 'DET'), ('``', '.'), ('creativity', 'NOUN'), ('and', 'CONJ'), ('inventiveness', 'NOUN'), ('of', 'ADP'), ('an', 'DET'), ('-LCB-', '.'), ('offending', 'VERB'), ('-RCB-', '.'), ('country', 'NOUN'), (\"'s\", 'PRT'), ('own', 'ADJ'), ('citizens', 'NOUN'), ('.', '.'), (\"''\", '.')], [('``', '.'), ('The', 'DET'), ('public', 'NOUN'), ('did', 'VERB'), (\"n't\", 'ADV'), ('come', 'VERB'), ('to', 'PRT'), ('the', 'DET'), ('market', 'NOUN'), ('*-1', 'X'), ('to', 'PRT'), ('play', 'VERB'), ('a', 'DET'), ('game', 'NOUN'), (';', '.'), ('they', 'PRON'), ('can', 'VERB'), ('go', 'VERB'), ('to', 'PRT'), ('Off-Track', 'NOUN'), ('Betting', 'NOUN'), ('for', 'ADP'), ('that', 'DET'), (',', '.'), (\"''\", '.'), ('says', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('A.', 'NOUN'), ('Brean', 'NOUN'), ('Murray', 'NOUN'), (',', '.'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Brean', 'NOUN'), ('Murray', 'NOUN'), (',', '.'), ('Foster', 'NOUN'), ('Securities', 'NOUN'), (',', '.'), ('a', 'DET'), ('traditional', 'ADJ'), ('money', 'NOUN'), ('management', 'NOUN'), ('firm', 'NOUN'), ('.', '.')], [('But', 'CONJ'), ('the', 'DET'), ('presidency', 'NOUN'), ('would', 'VERB'), ('be', 'VERB'), ('no', 'ADV'), ('worse', 'ADJ'), ('off', 'ADP'), ('than', 'ADP'), ('it', 'PRON'), ('is', 'VERB'), ('*?*', 'X'), ('now', 'ADV'), ('.', '.')], [('Eaton', 'NOUN'), ('Corp.', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('sold', 'VERB'), ('its', 'PRON'), ('Pacific', 'NOUN'), ('Sierra', 'NOUN'), ('Research', 'NOUN'), ('Corp.', 'NOUN'), ('unit', 'NOUN'), ('to', 'PRT'), ('a', 'DET'), ('company', 'NOUN'), ('formed', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('employees', 'NOUN'), ('of', 'ADP'), ('that', 'DET'), ('unit', 'NOUN'), ('.', '.')], [('He', 'PRON'), ('adds', 'VERB'), ('that', 'ADP'), ('his', 'PRON'), ('shares', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('company', 'NOUN'), ('savings', 'NOUN'), ('plan', 'NOUN'), ('are', 'VERB'), ('invested', 'VERB'), ('*-1', 'X'), ('in', 'ADP'), ('a', 'DET'), ('mutual', 'ADJ'), ('fund', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('volatility', 'NOUN'), (',', '.'), ('on', 'ADP'), ('a', 'DET'), ('given', 'VERB'), ('day', 'NOUN'), (',', '.'), ('may', 'VERB'), ('hurt', 'VERB'), ('the', 'DET'), ('fund', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "\n",
    "train_set, test_set = train_test_split(wsj,test_size=0.05,random_state=4)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95575"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yesterday',\n",
       " \"'s\",\n",
       " 'share',\n",
       " 'turnover',\n",
       " 'was',\n",
       " 'well',\n",
       " 'below',\n",
       " 'the',\n",
       " 'year',\n",
       " \"'s\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12082\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X', 'PRT', 'VERB', 'CONJ', 'NOUN', 'NUM', 'ADJ', 'ADP', 'DET', 'ADV', '.', 'PRON'}\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function Generates a dictionary which consist of Tags as keys and the list of words that are tagged under the specific tag\n",
    "#This dictionary helps will calculating the emission probability\n",
    "def tag_list_gen(T,train_bag = train_tagged_words):\n",
    "    tag_list={}\n",
    "    for tag in T:\n",
    "        tag_occur=[pair[0] for pair in train_bag if pair[1]==tag]\n",
    "        tag_list[tag]=tag_occur\n",
    "        \n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list=tag_list_gen(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words,tags_list=tags_list):\n",
    "    tag_list = tags_list[tag]\n",
    "    count_tag = len(tag_list)\n",
    "    \n",
    "    count_w_given_tag = tag_list.count(word)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a list with the tag order to compute Transition Probability\n",
    "tag_order=[pair[1] for pair in train_tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words,tags=tag_order):\n",
    "    \n",
    "    count_t1 = len(tags_list[t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.464737892150879\n"
     ]
    }
   ],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "start=time.time()\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.51665086e-02, 1.84110373e-01, 2.03298450e-01, 1.06248017e-02,\n",
       "        6.26387596e-02, 2.69584521e-03, 1.66508090e-02, 1.43672690e-01,\n",
       "        5.47097996e-02, 2.55312398e-02, 1.64605141e-01, 5.62955923e-02],\n",
       "       [1.37434555e-02, 1.96335069e-03, 4.00523573e-01, 2.29057600e-03,\n",
       "        2.46727750e-01, 5.85732982e-02, 8.47513080e-02, 2.02879589e-02,\n",
       "        1.01112567e-01, 9.16230399e-03, 4.28664908e-02, 1.79973822e-02],\n",
       "       [2.18669772e-01, 3.15830410e-02, 1.68728128e-01, 5.36756124e-03,\n",
       "        1.10073902e-01, 2.27926876e-02, 6.52664304e-02, 9.20264497e-02,\n",
       "        1.33877873e-01, 8.05912092e-02, 3.46168801e-02, 3.64060663e-02],\n",
       "       [8.40336177e-03, 5.13538765e-03, 1.59197018e-01, 4.66853409e-04,\n",
       "        3.42670411e-01, 4.29505147e-02, 1.19514473e-01, 5.18207289e-02,\n",
       "        1.20915033e-01, 5.60224093e-02, 3.50140072e-02, 5.78898229e-02],\n",
       "       [2.92066745e-02, 4.37004864e-02, 1.46544486e-01, 4.20941189e-02,\n",
       "        2.65342623e-01, 9.30962712e-03, 1.22668026e-02, 1.76663861e-01,\n",
       "        1.30699864e-02, 1.72319375e-02, 2.39823297e-01, 4.74608457e-03],\n",
       "       [2.11300761e-01, 2.76633315e-02, 1.64802819e-02, 1.38316657e-02,\n",
       "        3.53737503e-01, 1.84814602e-01, 3.38434391e-02, 3.53148915e-02,\n",
       "        3.53148906e-03, 2.94290762e-03, 1.15361981e-01, 1.17716298e-03],\n",
       "       [2.16636341e-02, 1.09145027e-02, 1.19067309e-02, 1.68678686e-02,\n",
       "        6.99520409e-01, 2.08367780e-02, 6.46601617e-02, 7.93782026e-02,\n",
       "        4.79576644e-03, 4.46502399e-03, 6.43294230e-02, 6.61485014e-04],\n",
       "       [3.42948735e-02, 1.49572652e-03, 8.44017137e-03, 8.54700862e-04,\n",
       "        3.21688026e-01, 6.43162429e-02, 1.05341882e-01, 1.70940179e-02,\n",
       "        3.23290586e-01, 1.41025642e-02, 4.11324799e-02, 6.79487213e-02],\n",
       "       [4.60422970e-02, 2.41691843e-04, 3.93957719e-02, 4.83383687e-04,\n",
       "        6.38549864e-01, 2.23564953e-02, 2.03504533e-01, 9.30513628e-03,\n",
       "        5.55891218e-03, 1.26888221e-02, 1.81268882e-02, 3.74622364e-03],\n",
       "       [2.33411137e-02, 1.33377789e-02, 3.46782267e-01, 7.00233411e-03,\n",
       "        3.23441140e-02, 3.03434487e-02, 1.29043013e-01, 1.18706234e-01,\n",
       "        6.93564489e-02, 7.93597847e-02, 1.35711908e-01, 1.46715576e-02],\n",
       "       [2.69469153e-02, 2.33539916e-03, 8.88349935e-02, 5.83849810e-02,\n",
       "        2.20156297e-01, 8.17389712e-02, 4.44624089e-02, 9.03619900e-02,\n",
       "        1.73897415e-01, 5.20075448e-02, 9.42243785e-02, 6.65588826e-02],\n",
       "       [9.18484479e-02, 1.26291616e-02, 4.83352482e-01, 4.97512426e-03,\n",
       "        2.10103333e-01, 7.65403733e-03, 7.42441639e-02, 2.29621120e-02,\n",
       "        9.95024852e-03, 3.48258689e-02, 3.94182913e-02, 8.03673919e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>ADV</th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.075167</td>\n",
       "      <td>0.184110</td>\n",
       "      <td>0.203298</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.062639</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.016651</td>\n",
       "      <td>0.143673</td>\n",
       "      <td>0.054710</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.164605</td>\n",
       "      <td>0.056296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.400524</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.246728</td>\n",
       "      <td>0.058573</td>\n",
       "      <td>0.084751</td>\n",
       "      <td>0.020288</td>\n",
       "      <td>0.101113</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>0.042866</td>\n",
       "      <td>0.017997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.218670</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>0.168728</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.110074</td>\n",
       "      <td>0.022793</td>\n",
       "      <td>0.065266</td>\n",
       "      <td>0.092026</td>\n",
       "      <td>0.133878</td>\n",
       "      <td>0.080591</td>\n",
       "      <td>0.034617</td>\n",
       "      <td>0.036406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.159197</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.342670</td>\n",
       "      <td>0.042951</td>\n",
       "      <td>0.119514</td>\n",
       "      <td>0.051821</td>\n",
       "      <td>0.120915</td>\n",
       "      <td>0.056022</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.057890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.029207</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.146544</td>\n",
       "      <td>0.042094</td>\n",
       "      <td>0.265343</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.012267</td>\n",
       "      <td>0.176664</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.017232</td>\n",
       "      <td>0.239823</td>\n",
       "      <td>0.004746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.211301</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.353738</td>\n",
       "      <td>0.184815</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>0.035315</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.115362</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.021664</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.011907</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.699520</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.064660</td>\n",
       "      <td>0.079378</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.064329</td>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.034295</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.321688</td>\n",
       "      <td>0.064316</td>\n",
       "      <td>0.105342</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.323291</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.041132</td>\n",
       "      <td>0.067949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.046042</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.039396</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.638550</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.203505</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.003746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.023341</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.346782</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.129043</td>\n",
       "      <td>0.118706</td>\n",
       "      <td>0.069356</td>\n",
       "      <td>0.079360</td>\n",
       "      <td>0.135712</td>\n",
       "      <td>0.014672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.026947</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>0.220156</td>\n",
       "      <td>0.081739</td>\n",
       "      <td>0.044462</td>\n",
       "      <td>0.090362</td>\n",
       "      <td>0.173897</td>\n",
       "      <td>0.052008</td>\n",
       "      <td>0.094224</td>\n",
       "      <td>0.066559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.091848</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.483352</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.210103</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.074244</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>0.039418</td>\n",
       "      <td>0.008037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X       PRT      VERB      CONJ      NOUN       NUM       ADJ  \\\n",
       "X     0.075167  0.184110  0.203298  0.010625  0.062639  0.002696  0.016651   \n",
       "PRT   0.013743  0.001963  0.400524  0.002291  0.246728  0.058573  0.084751   \n",
       "VERB  0.218670  0.031583  0.168728  0.005368  0.110074  0.022793  0.065266   \n",
       "CONJ  0.008403  0.005135  0.159197  0.000467  0.342670  0.042951  0.119514   \n",
       "NOUN  0.029207  0.043700  0.146544  0.042094  0.265343  0.009310  0.012267   \n",
       "NUM   0.211301  0.027663  0.016480  0.013832  0.353738  0.184815  0.033843   \n",
       "ADJ   0.021664  0.010915  0.011907  0.016868  0.699520  0.020837  0.064660   \n",
       "ADP   0.034295  0.001496  0.008440  0.000855  0.321688  0.064316  0.105342   \n",
       "DET   0.046042  0.000242  0.039396  0.000483  0.638550  0.022356  0.203505   \n",
       "ADV   0.023341  0.013338  0.346782  0.007002  0.032344  0.030343  0.129043   \n",
       ".     0.026947  0.002335  0.088835  0.058385  0.220156  0.081739  0.044462   \n",
       "PRON  0.091848  0.012629  0.483352  0.004975  0.210103  0.007654  0.074244   \n",
       "\n",
       "           ADP       DET       ADV         .      PRON  \n",
       "X     0.143673  0.054710  0.025531  0.164605  0.056296  \n",
       "PRT   0.020288  0.101113  0.009162  0.042866  0.017997  \n",
       "VERB  0.092026  0.133878  0.080591  0.034617  0.036406  \n",
       "CONJ  0.051821  0.120915  0.056022  0.035014  0.057890  \n",
       "NOUN  0.176664  0.013070  0.017232  0.239823  0.004746  \n",
       "NUM   0.035315  0.003531  0.002943  0.115362  0.001177  \n",
       "ADJ   0.079378  0.004796  0.004465  0.064329  0.000661  \n",
       "ADP   0.017094  0.323291  0.014103  0.041132  0.067949  \n",
       "DET   0.009305  0.005559  0.012689  0.018127  0.003746  \n",
       "ADV   0.118706  0.069356  0.079360  0.135712  0.014672  \n",
       ".     0.090362  0.173897  0.052008  0.094224  0.066559  \n",
       "PRON  0.022962  0.009950  0.034826  0.039418  0.008037  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X       0.026947\n",
       "PRT     0.002335\n",
       "VERB    0.088835\n",
       "CONJ    0.058385\n",
       "NOUN    0.220156\n",
       "NUM     0.081739\n",
       "ADJ     0.044462\n",
       "ADP     0.090362\n",
       "DET     0.173897\n",
       "ADV     0.052008\n",
       ".       0.094224\n",
       "PRON    0.066559\n",
       "Name: ., dtype: float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.loc['.', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Viterbi Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Vannila Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged_words,tags=T):\n",
    "    state = []\n",
    "    T = list(tags)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            word_prob= word_given_tag(words[key], tag)\n",
    "            emission_p = word_prob[0]/word_prob[1]\n",
    "            \n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        \n",
    "        \n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "        \n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Algorithm with laplacian smoothing\n",
    "def Laplacian_Viterbi(words, train_bag = train_tagged_words,tags=T):\n",
    "    state = []\n",
    "    T = list(tags)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            word_prob= word_given_tag(words[key], tag)\n",
    "            emission_p = word_prob[0]/word_prob[1]\n",
    "            if not emission_p:\n",
    "                emission_p=0.0000000000001\n",
    "            \n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        \n",
    "        \n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "        \n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patterns for regexp Tagger\n",
    "patterns = [(r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "      (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "      (r'.*able$', 'ADJ'),                # adjectives\n",
    "      (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "      (r'.*ly$', 'ADV'),                  # adverbs\n",
    "      (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "      (r'.*ing$', 'VERB'),                # gerunds\n",
    "      (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "      (r'.*', 'NOUN'),                     # nouns (default)\n",
    "      (r'.*\\*.*\\*','X')      \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Regexp Tagger\n",
    "rex=nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42462262301509507"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rex.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize unigram tagger with regexp tagger as backoff\n",
    "unigram=nltk.UnigramTagger(train_set,backoff=rex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9554989217800431"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi alogrithm with rule based pos-tagging\n",
    "def Rule_Viterbi(words, train_bag = train_tagged_words,tags=T):\n",
    "    state = []\n",
    "    T = list(tags)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            word_prob= word_given_tag(words[key], tag)\n",
    "            emission_p = word_prob[0]/word_prob[1]\n",
    "            \n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        if not pmax:\n",
    "                \n",
    "                state.append(unigram.tag([words[key]])[0][1])\n",
    "        else:\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "        \n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of sents\n",
    "test_run = test_set\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "#test_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  29.68366241455078\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "#print(tagged_seq)\n",
    "#print(test_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vannila = len(check)/len(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9119780435208783"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_vannila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Laplacian_Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  31.630450963974\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "#print(tagged_seq)\n",
    "#print(test_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_laplacian = len(check)/len(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9445206822191727"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Rule_Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  31.4149968624115\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "#print(tagged_seq)\n",
    "#print(test_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rule = len(check)/len(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580474416781023"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on sample sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fopen=open('Test_sentences.txt','r')#Open the test sentence file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence=fopen.read() #Storing all sentences in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Android is a mobile operating system developed by Google.\\nAndroid has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.\\nGoogle and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\\nTwitter is an online news and social networking service on which users post and interact with messages known as tweets.\\nBefore entering politics, Donald Trump was a domineering businessman and a television personality.\\nThe 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\\nThis is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.\\nShow me the cheapest round trips from Dallas to Atlanta\\nI would like to see flights from Denver to Philadelphia.\\nShow me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.\\nNASA invited social media users to experience the launch of ICESAT-2 Satellite.\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mobile',\n",
       " 'operating',\n",
       " 'system',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'Google',\n",
       " '.',\n",
       " 'Android',\n",
       " 'has',\n",
       " 'been',\n",
       " 'the',\n",
       " 'best-selling',\n",
       " 'OS',\n",
       " 'worldwide',\n",
       " 'on',\n",
       " 'smartphones',\n",
       " 'since']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=word_tokenize(test_sentence)#Tokenize the given sentences\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fopen.close()#Closing the File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq_vannila = Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'X'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'X'), ('.', '.'), ('Android', 'X'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'X'), ('worldwide', 'X'), ('on', 'ADP'), ('smartphones', 'X'), ('since', 'ADP'), ('2011', 'X'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'X'), ('.', '.'), ('Google', 'X'), ('and', 'CONJ'), ('Twitter', 'X'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'X'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'X'), (\"'s\", 'PRT'), ('firehose', 'X'), ('.', '.'), ('Twitter', 'X'), ('is', 'VERB'), ('an', 'DET'), ('online', 'X'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'X'), ('with', 'ADP'), ('messages', 'X'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'X'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'X'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'X'), ('.', '.'), ('The', 'DET'), ('2018', 'X'), ('FIFA', 'X'), ('World', 'NOUN'), ('Cup', 'X'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'X'), ('FIFA', 'X'), ('World', 'NOUN'), ('Cup', 'X'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'X'), ('contested', 'X'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'X'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'X'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'X'), ('invited', 'X'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'X'), ('Satellite', 'X'), ('.', '.')]\n",
      "1.2806079387664795\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq_vannila)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Based Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq_rule = Rule_Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.'), ('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'NOUN'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "1.2626228332519531\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq_rule)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq_Laplacian = Laplacian_Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'DET'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'DET'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.'), ('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'DET'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'DET'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'NOUN'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "1.036240577697754\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq_Laplacian)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vannila vs Laplacian\n",
    "Sample Cases where laplacian has tagged correctly over vannila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VANNILA - (ANDROID,X),(NASA,X),(TWITTER,X)\n",
    "\n",
    "\n",
    "LAPLACIAN -(ANDROID,NOUN),(NASA,NOUN),(TWITTER,NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Based Vs Vannila\n",
    "Sample Cases where Rule-based has tagged correctly over vannila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VANNILA - (domineering, X),(invited,X),(FIFA,X)\n",
    "\n",
    "Rule-Based - (domineering, VERB),(invited,VERB),(FIFA,NOUN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
